{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing the dataset movies\n",
    "\n",
    "movies=pd.read_csv('movies.dat',sep='::', header=None, engine = 'python', encoding='latin-1')\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset users\n",
    "\n",
    "users=pd.read_csv('users.dat',sep='::', header=None, engine = 'python', encoding='latin-1')\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Importing the dataset ratings\n",
    "\n",
    "ratings=pd.read_csv('ratings.dat',sep='::', header=None, engine = 'python', encoding='latin-1')\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare train and test data \n",
    "\n",
    "train=pd.read_csv('u11.base', delimiter='\\t')\n",
    "\n",
    "train=np.array(train,dtype='int')\n",
    "\n",
    "train.dtype\n",
    "\n",
    "test=pd.read_csv('u11.test', delimiter='\\t')\n",
    "\n",
    "test=np.array(test,dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find the number of user and movies\n",
    "\n",
    "nb_users=int(max(max(train[:,0]),max(test[:,0])))\n",
    "\n",
    "nb_movies=int(max(max(train[:,1]),max(test[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocessing the input into an array with userids and movies\n",
    "\n",
    "def convert(data):\n",
    "    new_data=[]\n",
    "    for id_users in range(1,nb_users+1):\n",
    "        id_movies = data[:,1][data[:,0]==id_users]\n",
    "        id_ratings = data[:,2][data[:,0]==id_users]\n",
    "        ratings=np.zeros(nb_movies)\n",
    "        ratings[id_movies-1]=id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "\n",
    "        \n",
    "\n",
    "train=convert(train)\n",
    "\n",
    "test=convert(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transform the arrays into torch tensors\n",
    "\n",
    "train=torch.FloatTensor(train)\n",
    "\n",
    "test=torch.FloatTensor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding the ratings to liked and hated \n",
    "\n",
    "train[train==0]=-1\n",
    "train[train==1]=0\n",
    "train[train==2]=0\n",
    "train[train>3]=1\n",
    "\n",
    "test[test==0]=-1\n",
    "test[test==1]=0\n",
    "test[test==2]=0\n",
    "test[test>=3]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Creating the RBM Network\n",
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(1, nh)\n",
    "        self.b = torch.randn(1, nv)\n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fit the rbm network on the data \n",
    "\n",
    "nv = len(train[0])\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 0.738309168467\n",
      "epoch: 2 loss: 0.73672665848\n",
      "epoch: 3 loss: 0.735321356125\n",
      "epoch: 4 loss: 0.734854222959\n",
      "epoch: 5 loss: 0.734601580259\n",
      "epoch: 6 loss: 0.734905409309\n",
      "epoch: 7 loss: 0.734382533621\n",
      "epoch: 8 loss: 0.735892582015\n",
      "epoch: 9 loss: 0.736662881672\n",
      "epoch: 10 loss: 0.737249751079\n",
      "epoch: 11 loss: 0.737007958016\n",
      "epoch: 12 loss: 0.73786823908\n",
      "epoch: 13 loss: 0.738464362957\n",
      "epoch: 14 loss: 0.738335813775\n",
      "epoch: 15 loss: 0.738593420767\n",
      "epoch: 16 loss: 0.739138265681\n",
      "epoch: 17 loss: 0.739736768351\n",
      "epoch: 18 loss: 0.740315328112\n",
      "epoch: 19 loss: 0.73990730635\n",
      "epoch: 20 loss: 0.740558909134\n",
      "epoch: 21 loss: 0.74082710649\n",
      "epoch: 22 loss: 0.740501617797\n",
      "epoch: 23 loss: 0.740102625841\n",
      "epoch: 24 loss: 0.739416807574\n",
      "epoch: 25 loss: 0.739348358624\n",
      "epoch: 26 loss: 0.739536368047\n",
      "epoch: 27 loss: 0.739961204425\n",
      "epoch: 28 loss: 0.739664800041\n",
      "epoch: 29 loss: 0.73988725723\n",
      "epoch: 30 loss: 0.73937598976\n",
      "epoch: 31 loss: 0.739649474848\n",
      "epoch: 32 loss: 0.739221191329\n",
      "epoch: 33 loss: 0.738910745378\n",
      "epoch: 34 loss: 0.738701423105\n",
      "epoch: 35 loss: 0.738738592624\n",
      "epoch: 36 loss: 0.739329368397\n",
      "epoch: 37 loss: 0.738857498078\n",
      "epoch: 38 loss: 0.739030448413\n",
      "epoch: 39 loss: 0.739294709403\n",
      "epoch: 40 loss: 0.739263286326\n",
      "epoch: 41 loss: 0.739077386293\n",
      "epoch: 42 loss: 0.739176852501\n",
      "epoch: 43 loss: 0.739268294292\n",
      "epoch: 44 loss: 0.739001707627\n",
      "epoch: 45 loss: 0.738109885795\n",
      "epoch: 46 loss: 0.738074807396\n",
      "epoch: 47 loss: 0.737929743759\n",
      "epoch: 48 loss: 0.738244653598\n",
      "epoch: 49 loss: 0.738749510718\n",
      "epoch: 50 loss: 0.738960730506\n",
      "epoch: 51 loss: 0.7390252058\n",
      "epoch: 52 loss: 0.738892805348\n",
      "epoch: 53 loss: 0.738871686957\n",
      "epoch: 54 loss: 0.73895534323\n",
      "epoch: 55 loss: 0.739122361816\n",
      "epoch: 56 loss: 0.739406498376\n",
      "epoch: 57 loss: 0.73986757072\n",
      "epoch: 58 loss: 0.739924950819\n",
      "epoch: 59 loss: 0.739929112071\n",
      "epoch: 60 loss: 0.739906836349\n",
      "epoch: 61 loss: 0.740272260404\n",
      "epoch: 62 loss: 0.74032650268\n",
      "epoch: 63 loss: 0.74055047764\n",
      "epoch: 64 loss: 0.740502885825\n",
      "epoch: 65 loss: 0.740855196614\n",
      "epoch: 66 loss: 0.740994530289\n",
      "epoch: 67 loss: 0.741121826151\n",
      "epoch: 68 loss: 0.741188832884\n",
      "epoch: 69 loss: 0.741589860752\n",
      "epoch: 70 loss: 0.74141257839\n",
      "epoch: 71 loss: 0.741476243349\n",
      "epoch: 72 loss: 0.741593796289\n",
      "epoch: 73 loss: 0.74171279128\n",
      "epoch: 74 loss: 0.741584391766\n",
      "epoch: 75 loss: 0.741641996441\n",
      "epoch: 76 loss: 0.741793880181\n",
      "epoch: 77 loss: 0.741576992403\n",
      "epoch: 78 loss: 0.741509728392\n",
      "epoch: 79 loss: 0.741512637131\n",
      "epoch: 80 loss: 0.741641403638\n",
      "epoch: 81 loss: 0.742010701049\n",
      "epoch: 82 loss: 0.741970963736\n",
      "epoch: 83 loss: 0.741767888374\n",
      "epoch: 84 loss: 0.74179323784\n",
      "epoch: 85 loss: 0.742034503487\n",
      "epoch: 86 loss: 0.742141887191\n",
      "epoch: 87 loss: 0.742696414065\n",
      "epoch: 88 loss: 0.742662589753\n",
      "epoch: 89 loss: 0.742649098268\n",
      "epoch: 90 loss: 0.742707967772\n",
      "epoch: 91 loss: 0.742983295515\n",
      "epoch: 92 loss: 0.743279557344\n",
      "epoch: 93 loss: 0.743319237594\n",
      "epoch: 94 loss: 0.743246524629\n",
      "epoch: 95 loss: 0.743741960199\n",
      "epoch: 96 loss: 0.743762972118\n",
      "epoch: 97 loss: 0.743804713035\n",
      "epoch: 98 loss: 0.743541906111\n",
      "epoch: 99 loss: 0.743479350431\n",
      "epoch: 100 loss: 0.743679704845\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train the RBM model\n",
    "nb_epoch = 100\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = train[id_user:id_user+batch_size]\n",
    "        v0 = train[id_user:id_user+batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "        s += 1.\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.19290748262\n"
     ]
    }
   ],
   "source": [
    "# Test the RBM model\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    v = train[id_user:id_user+1]\n",
    "    vt = test[id_user:id_user+1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
